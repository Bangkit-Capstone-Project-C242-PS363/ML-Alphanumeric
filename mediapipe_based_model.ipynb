{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip asl_split_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVF6FvE6TET5",
        "outputId": "61438618-1149-462d-daf3-9864d320062b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  asl_split_dataset.zip\n",
            "   creating: asl_split_dataset/\n",
            "   creating: asl_split_dataset/test/\n",
            "   creating: asl_split_dataset/test/0/\n",
            "  inflating: asl_split_dataset/test/0/hand1_0_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand1_0_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand1_0_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand1_0_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand1_0_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand1_0_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand2_0_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/0/hand4_0_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/1/\n",
            "  inflating: asl_split_dataset/test/1/hand1_1_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand1_1_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand1_1_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand1_1_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand1_1_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand1_1_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand2_1_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/1/hand4_1_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/2/\n",
            "  inflating: asl_split_dataset/test/2/hand1_2_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand1_2_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand1_2_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand1_2_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand1_2_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand1_2_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand2_2_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/2/hand4_2_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/3/\n",
            "  inflating: asl_split_dataset/test/3/hand1_3_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand1_3_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand1_3_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand1_3_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand1_3_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand1_3_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand2_3_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/3/hand4_3_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/4/\n",
            "  inflating: asl_split_dataset/test/4/hand1_4_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand1_4_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand1_4_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand1_4_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand1_4_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand1_4_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand2_4_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/4/hand4_4_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/5/\n",
            "  inflating: asl_split_dataset/test/5/hand1_5_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand1_5_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand1_5_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand1_5_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand1_5_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand1_5_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand2_5_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/5/hand4_5_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/6/\n",
            "  inflating: asl_split_dataset/test/6/hand1_6_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand1_6_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand1_6_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand1_6_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand1_6_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand1_6_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand2_6_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/6/hand4_6_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/7/\n",
            "  inflating: asl_split_dataset/test/7/hand1_7_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand1_7_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand1_7_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand1_7_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand1_7_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand1_7_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand2_7_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/7/hand4_7_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/8/\n",
            "  inflating: asl_split_dataset/test/8/hand1_8_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand1_8_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand1_8_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand1_8_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand1_8_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand1_8_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand2_8_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/8/hand4_8_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/9/\n",
            "  inflating: asl_split_dataset/test/9/hand1_9_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand1_9_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand1_9_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand1_9_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand1_9_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand1_9_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand2_9_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/9/hand4_9_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/a/\n",
            "  inflating: asl_split_dataset/test/a/hand1_a_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand1_a_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand1_a_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand1_a_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand1_a_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand1_a_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand2_a_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/a/hand4_a_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/b/\n",
            "  inflating: asl_split_dataset/test/b/hand1_b_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand1_b_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand1_b_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand1_b_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand1_b_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand1_b_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand2_b_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/b/hand4_b_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/c/\n",
            "  inflating: asl_split_dataset/test/c/hand1_c_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand1_c_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand1_c_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand1_c_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand1_c_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand1_c_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand2_c_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/c/hand4_c_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/d/\n",
            "  inflating: asl_split_dataset/test/d/hand1_d_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand1_d_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand1_d_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand1_d_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand1_d_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand1_d_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand2_d_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/d/hand4_d_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/e/\n",
            "  inflating: asl_split_dataset/test/e/hand1_e_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand1_e_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand1_e_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand1_e_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand1_e_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand1_e_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand2_e_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/e/hand4_e_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/f/\n",
            "  inflating: asl_split_dataset/test/f/hand1_f_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand1_f_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand1_f_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand1_f_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand1_f_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand1_f_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand2_f_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/f/hand4_f_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/g/\n",
            "  inflating: asl_split_dataset/test/g/hand1_g_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand1_g_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand1_g_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand1_g_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand1_g_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand1_g_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand2_g_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/g/hand4_g_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/h/\n",
            "  inflating: asl_split_dataset/test/h/hand1_h_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand1_h_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand1_h_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand1_h_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand1_h_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand1_h_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand2_h_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/h/hand4_h_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/i/\n",
            "  inflating: asl_split_dataset/test/i/hand1_i_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand1_i_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand1_i_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand1_i_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand1_i_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand1_i_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand2_i_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/i/hand4_i_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/j/\n",
            "  inflating: asl_split_dataset/test/j/hand1_j_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand1_j_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand1_j_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand1_j_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand1_j_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand1_j_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand2_j_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/j/hand4_j_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/k/\n",
            "  inflating: asl_split_dataset/test/k/hand1_k_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand1_k_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand1_k_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand1_k_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand1_k_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand1_k_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand2_k_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/k/hand4_k_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/l/\n",
            "  inflating: asl_split_dataset/test/l/hand1_l_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand1_l_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand1_l_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand1_l_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand1_l_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand1_l_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand2_l_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/l/hand4_l_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/m/\n",
            "  inflating: asl_split_dataset/test/m/hand1_m_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand1_m_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand1_m_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand1_m_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand1_m_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand1_m_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand2_m_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/m/hand4_m_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/n/\n",
            "  inflating: asl_split_dataset/test/n/hand1_n_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand1_n_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand1_n_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand1_n_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand1_n_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand1_n_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand2_n_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/n/hand4_n_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/o/\n",
            "  inflating: asl_split_dataset/test/o/hand1_o_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand1_o_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand1_o_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand1_o_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand1_o_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand1_o_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand2_o_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/o/hand4_o_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/p/\n",
            "  inflating: asl_split_dataset/test/p/hand1_p_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand1_p_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand1_p_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand1_p_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand1_p_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand1_p_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand2_p_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/p/hand4_p_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/q/\n",
            "  inflating: asl_split_dataset/test/q/hand1_q_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand1_q_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand1_q_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand1_q_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand1_q_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand1_q_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand2_q_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/q/hand4_q_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/r/\n",
            "  inflating: asl_split_dataset/test/r/hand1_r_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand1_r_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand1_r_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand1_r_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand1_r_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand1_r_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand2_r_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/r/hand4_r_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/s/\n",
            "  inflating: asl_split_dataset/test/s/hand1_s_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand1_s_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand1_s_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand1_s_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand1_s_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand1_s_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand2_s_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/s/hand4_s_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/t/\n",
            "  inflating: asl_split_dataset/test/t/hand1_t_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand1_t_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand1_t_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand1_t_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand1_t_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand1_t_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand1_t_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand2_t_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand2_t_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand2_t_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand3_t_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand5_t_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand5_t_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/t/hand5_t_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/u/\n",
            "  inflating: asl_split_dataset/test/u/hand1_u_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand1_u_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand1_u_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand1_u_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand1_u_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand1_u_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand2_u_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/u/hand4_u_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/v/\n",
            "  inflating: asl_split_dataset/test/v/hand1_v_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand1_v_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand1_v_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand1_v_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand1_v_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand1_v_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand2_v_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/v/hand4_v_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/w/\n",
            "  inflating: asl_split_dataset/test/w/hand1_w_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand1_w_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand1_w_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand1_w_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand1_w_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand1_w_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand2_w_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/w/hand4_w_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/x/\n",
            "  inflating: asl_split_dataset/test/x/hand1_x_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand1_x_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand1_x_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand1_x_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand1_x_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand1_x_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand2_x_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/x/hand4_x_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/y/\n",
            "  inflating: asl_split_dataset/test/y/hand1_y_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand1_y_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand1_y_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand1_y_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand1_y_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand1_y_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand2_y_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/y/hand4_y_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/test/z/\n",
            "  inflating: asl_split_dataset/test/z/hand1_z_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand1_z_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand1_z_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand1_z_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand1_z_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand1_z_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand2_z_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/test/z/hand4_z_bot_seg_3_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/\n",
            "   creating: asl_split_dataset/train/0/\n",
            "  inflating: asl_split_dataset/train/0/hand1_0_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand1_0_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand2_0_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand3_0_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand3_0_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand3_0_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand3_0_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand4_0_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand4_0_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand4_0_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/0/hand5_0_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/1/\n",
            "  inflating: asl_split_dataset/train/1/hand1_1_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand1_1_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand2_1_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand3_1_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand3_1_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand3_1_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand3_1_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand4_1_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand4_1_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand4_1_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/1/hand5_1_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/2/\n",
            "  inflating: asl_split_dataset/train/2/hand1_2_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand1_2_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand2_2_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand3_2_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand3_2_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand3_2_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand3_2_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand4_2_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand4_2_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand4_2_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/2/hand5_2_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/3/\n",
            "  inflating: asl_split_dataset/train/3/hand1_3_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand1_3_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand2_3_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand3_3_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand3_3_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand3_3_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand3_3_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand4_3_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand4_3_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand4_3_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/3/hand5_3_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/4/\n",
            "  inflating: asl_split_dataset/train/4/hand1_4_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand1_4_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand2_4_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand3_4_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand3_4_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand3_4_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand3_4_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand4_4_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand4_4_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand4_4_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/4/hand5_4_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/5/\n",
            "  inflating: asl_split_dataset/train/5/hand1_5_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand1_5_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand2_5_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand3_5_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand3_5_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand3_5_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand3_5_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand4_5_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand4_5_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand4_5_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/5/hand5_5_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/6/\n",
            "  inflating: asl_split_dataset/train/6/hand1_6_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand1_6_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand2_6_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand3_6_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand3_6_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand3_6_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand3_6_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand4_6_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand4_6_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand4_6_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/6/hand5_6_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/7/\n",
            "  inflating: asl_split_dataset/train/7/hand1_7_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand1_7_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand2_7_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand3_7_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand3_7_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand3_7_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand3_7_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand4_7_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand4_7_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand4_7_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/7/hand5_7_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/8/\n",
            "  inflating: asl_split_dataset/train/8/hand1_8_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand1_8_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand2_8_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand3_8_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand3_8_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand3_8_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand3_8_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand4_8_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand4_8_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand4_8_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/8/hand5_8_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/9/\n",
            "  inflating: asl_split_dataset/train/9/hand1_9_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand1_9_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand2_9_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand3_9_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand3_9_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand3_9_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand3_9_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand4_9_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand4_9_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand4_9_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/9/hand5_9_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/a/\n",
            "  inflating: asl_split_dataset/train/a/hand1_a_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand1_a_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand2_a_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand3_a_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand3_a_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand3_a_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand3_a_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand4_a_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand4_a_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand4_a_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/a/hand5_a_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/b/\n",
            "  inflating: asl_split_dataset/train/b/hand1_b_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand1_b_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand2_b_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand3_b_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand3_b_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand3_b_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand3_b_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand4_b_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand4_b_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand4_b_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/b/hand5_b_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/c/\n",
            "  inflating: asl_split_dataset/train/c/hand1_c_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand1_c_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand2_c_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand3_c_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand3_c_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand3_c_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand3_c_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand4_c_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand4_c_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand4_c_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/c/hand5_c_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/d/\n",
            "  inflating: asl_split_dataset/train/d/hand1_d_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand1_d_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand2_d_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand3_d_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand3_d_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand3_d_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand3_d_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand4_d_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand4_d_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand4_d_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/d/hand5_d_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/e/\n",
            "  inflating: asl_split_dataset/train/e/hand1_e_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand1_e_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand2_e_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand3_e_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand3_e_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand3_e_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand3_e_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand4_e_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand4_e_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand4_e_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/e/hand5_e_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/f/\n",
            "  inflating: asl_split_dataset/train/f/hand1_f_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand1_f_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand2_f_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand3_f_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand3_f_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand3_f_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand3_f_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand4_f_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand4_f_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand4_f_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/f/hand5_f_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/g/\n",
            "  inflating: asl_split_dataset/train/g/hand1_g_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand1_g_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand2_g_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand3_g_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand3_g_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand3_g_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand3_g_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand4_g_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand4_g_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand4_g_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/g/hand5_g_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/h/\n",
            "  inflating: asl_split_dataset/train/h/hand1_h_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand1_h_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand2_h_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand3_h_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand3_h_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand3_h_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand3_h_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand4_h_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand4_h_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand4_h_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/h/hand5_h_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/i/\n",
            "  inflating: asl_split_dataset/train/i/hand1_i_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand1_i_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand2_i_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand3_i_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand3_i_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand3_i_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand3_i_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand4_i_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand4_i_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand4_i_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/i/hand5_i_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/j/\n",
            "  inflating: asl_split_dataset/train/j/hand1_j_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand1_j_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand2_j_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand3_j_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand3_j_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand3_j_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand3_j_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand4_j_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand4_j_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand4_j_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/j/hand5_j_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/k/\n",
            "  inflating: asl_split_dataset/train/k/hand1_k_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand1_k_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand2_k_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand3_k_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand3_k_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand3_k_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand3_k_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand4_k_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand4_k_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand4_k_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/k/hand5_k_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/l/\n",
            "  inflating: asl_split_dataset/train/l/hand1_l_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand1_l_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand2_l_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand3_l_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand3_l_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand3_l_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand3_l_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand4_l_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand4_l_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand4_l_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/l/hand5_l_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/m/\n",
            "  inflating: asl_split_dataset/train/m/hand1_m_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand1_m_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand2_m_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand3_m_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand3_m_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand3_m_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand3_m_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand4_m_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand4_m_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand4_m_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/m/hand5_m_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/n/\n",
            "  inflating: asl_split_dataset/train/n/hand1_n_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand1_n_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand2_n_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand3_n_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand3_n_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand3_n_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand3_n_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand4_n_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand4_n_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand4_n_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/n/hand5_n_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/o/\n",
            "  inflating: asl_split_dataset/train/o/hand1_o_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand1_o_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand2_o_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand3_o_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand3_o_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand3_o_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand3_o_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand4_o_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand4_o_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand4_o_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/o/hand5_o_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/p/\n",
            "  inflating: asl_split_dataset/train/p/hand1_p_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand1_p_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand2_p_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand3_p_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand3_p_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand3_p_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand3_p_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand4_p_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand4_p_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand4_p_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/p/hand5_p_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/q/\n",
            "  inflating: asl_split_dataset/train/q/hand1_q_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand1_q_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand2_q_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand3_q_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand3_q_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand3_q_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand3_q_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand4_q_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand4_q_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand4_q_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/q/hand5_q_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/r/\n",
            "  inflating: asl_split_dataset/train/r/hand1_r_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand1_r_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand2_r_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand3_r_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand3_r_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand3_r_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand3_r_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand4_r_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand4_r_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand4_r_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/r/hand5_r_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/s/\n",
            "  inflating: asl_split_dataset/train/s/hand1_s_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand1_s_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand2_s_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand3_s_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand3_s_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand3_s_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand3_s_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand4_s_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand4_s_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand4_s_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/s/hand5_s_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/t/\n",
            "  inflating: asl_split_dataset/train/t/hand1_t_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand1_t_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand2_t_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand3_t_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand3_t_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand3_t_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand4_t_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand4_t_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand4_t_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand4_t_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand5_t_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand5_t_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand5_t_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand5_t_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand5_t_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/t/hand5_t_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/u/\n",
            "  inflating: asl_split_dataset/train/u/hand1_u_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand1_u_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand2_u_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand3_u_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand3_u_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand3_u_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand3_u_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand4_u_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand4_u_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand4_u_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/u/hand5_u_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/v/\n",
            "  inflating: asl_split_dataset/train/v/hand1_v_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand1_v_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand2_v_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand3_v_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand3_v_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand3_v_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand3_v_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand4_v_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand4_v_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand4_v_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/v/hand5_v_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/w/\n",
            "  inflating: asl_split_dataset/train/w/hand1_w_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand1_w_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand2_w_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand3_w_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand3_w_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand3_w_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand3_w_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand4_w_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand4_w_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand4_w_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/w/hand5_w_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/x/\n",
            "  inflating: asl_split_dataset/train/x/hand1_x_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand1_x_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand2_x_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand3_x_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand3_x_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand3_x_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand3_x_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand4_x_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand4_x_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand4_x_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/x/hand5_x_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/y/\n",
            "  inflating: asl_split_dataset/train/y/hand1_y_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand1_y_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand2_y_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand3_y_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand3_y_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand3_y_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand3_y_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand4_y_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand4_y_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand4_y_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/y/hand5_y_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/train/z/\n",
            "  inflating: asl_split_dataset/train/z/hand1_z_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_left_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_top_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand1_z_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_left_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_left_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_right_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_right_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_top_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_top_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand2_z_top_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand3_z_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand3_z_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand3_z_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand3_z_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand4_z_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand4_z_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand4_z_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_bot_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_bot_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_dif_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_dif_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/train/z/hand5_z_dif_seg_4_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/\n",
            "   creating: asl_split_dataset/val/0/\n",
            "  inflating: asl_split_dataset/val/0/hand1_0_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand1_0_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand2_0_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand2_0_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand2_0_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand2_0_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand3_0_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand4_0_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand5_0_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand5_0_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/0/hand5_0_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/1/\n",
            "  inflating: asl_split_dataset/val/1/hand1_1_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand1_1_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand2_1_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand2_1_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand2_1_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand2_1_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand3_1_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand4_1_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand5_1_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand5_1_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/1/hand5_1_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/2/\n",
            "  inflating: asl_split_dataset/val/2/hand1_2_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand1_2_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand2_2_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand2_2_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand2_2_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand2_2_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand3_2_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand4_2_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand5_2_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand5_2_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/2/hand5_2_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/3/\n",
            "  inflating: asl_split_dataset/val/3/hand1_3_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand1_3_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand2_3_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand2_3_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand2_3_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand2_3_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand3_3_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand4_3_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand5_3_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand5_3_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/3/hand5_3_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/4/\n",
            "  inflating: asl_split_dataset/val/4/hand1_4_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand1_4_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand2_4_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand2_4_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand2_4_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand2_4_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand3_4_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand4_4_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand5_4_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand5_4_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/4/hand5_4_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/5/\n",
            "  inflating: asl_split_dataset/val/5/hand1_5_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand1_5_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand2_5_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand2_5_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand2_5_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand2_5_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand3_5_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand4_5_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand5_5_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand5_5_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/5/hand5_5_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/6/\n",
            "  inflating: asl_split_dataset/val/6/hand1_6_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand1_6_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand2_6_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand2_6_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand2_6_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand2_6_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand3_6_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand4_6_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand5_6_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand5_6_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/6/hand5_6_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/7/\n",
            "  inflating: asl_split_dataset/val/7/hand1_7_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand1_7_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand2_7_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand2_7_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand2_7_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand2_7_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand3_7_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand4_7_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand5_7_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand5_7_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/7/hand5_7_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/8/\n",
            "  inflating: asl_split_dataset/val/8/hand1_8_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand1_8_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand2_8_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand2_8_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand2_8_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand2_8_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand3_8_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand4_8_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand5_8_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand5_8_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/8/hand5_8_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/9/\n",
            "  inflating: asl_split_dataset/val/9/hand1_9_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand1_9_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand2_9_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand2_9_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand2_9_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand2_9_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand3_9_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand4_9_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand5_9_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand5_9_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/9/hand5_9_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/a/\n",
            "  inflating: asl_split_dataset/val/a/hand1_a_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand1_a_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand2_a_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand2_a_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand2_a_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand2_a_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand3_a_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand4_a_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand5_a_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand5_a_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/a/hand5_a_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/b/\n",
            "  inflating: asl_split_dataset/val/b/hand1_b_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand1_b_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand2_b_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand2_b_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand2_b_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand2_b_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand3_b_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand4_b_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand5_b_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand5_b_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/b/hand5_b_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/c/\n",
            "  inflating: asl_split_dataset/val/c/hand1_c_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand1_c_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand2_c_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand2_c_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand2_c_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand2_c_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand3_c_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand4_c_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand5_c_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand5_c_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/c/hand5_c_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/d/\n",
            "  inflating: asl_split_dataset/val/d/hand1_d_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand1_d_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand2_d_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand2_d_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand2_d_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand2_d_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand3_d_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand4_d_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand5_d_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand5_d_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/d/hand5_d_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/e/\n",
            "  inflating: asl_split_dataset/val/e/hand1_e_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand1_e_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand2_e_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand2_e_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand2_e_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand2_e_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand3_e_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand4_e_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand5_e_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand5_e_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/e/hand5_e_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/f/\n",
            "  inflating: asl_split_dataset/val/f/hand1_f_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand1_f_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand2_f_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand2_f_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand2_f_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand2_f_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand3_f_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand4_f_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand5_f_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand5_f_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/f/hand5_f_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/g/\n",
            "  inflating: asl_split_dataset/val/g/hand1_g_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand1_g_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand2_g_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand2_g_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand2_g_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand2_g_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand3_g_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand4_g_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand5_g_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand5_g_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/g/hand5_g_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/h/\n",
            "  inflating: asl_split_dataset/val/h/hand1_h_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand1_h_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand2_h_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand2_h_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand2_h_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand2_h_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand3_h_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand4_h_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand5_h_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand5_h_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/h/hand5_h_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/i/\n",
            "  inflating: asl_split_dataset/val/i/hand1_i_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand1_i_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand2_i_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand2_i_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand2_i_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand2_i_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand3_i_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand4_i_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand5_i_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand5_i_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/i/hand5_i_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/j/\n",
            "  inflating: asl_split_dataset/val/j/hand1_j_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand1_j_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand2_j_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand2_j_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand2_j_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand2_j_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand3_j_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand4_j_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand5_j_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand5_j_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/j/hand5_j_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/k/\n",
            "  inflating: asl_split_dataset/val/k/hand1_k_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand1_k_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand2_k_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand2_k_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand2_k_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand2_k_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand3_k_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand4_k_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand5_k_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand5_k_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/k/hand5_k_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/l/\n",
            "  inflating: asl_split_dataset/val/l/hand1_l_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand1_l_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand2_l_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand2_l_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand2_l_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand2_l_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand3_l_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand4_l_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand5_l_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand5_l_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/l/hand5_l_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/m/\n",
            "  inflating: asl_split_dataset/val/m/hand1_m_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand1_m_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand2_m_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand2_m_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand2_m_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand2_m_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand3_m_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand4_m_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand5_m_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand5_m_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/m/hand5_m_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/n/\n",
            "  inflating: asl_split_dataset/val/n/hand1_n_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand1_n_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand2_n_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand2_n_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand2_n_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand2_n_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand3_n_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand4_n_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand5_n_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand5_n_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/n/hand5_n_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/o/\n",
            "  inflating: asl_split_dataset/val/o/hand1_o_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand1_o_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand2_o_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand2_o_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand2_o_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand2_o_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand3_o_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand4_o_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand5_o_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand5_o_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/o/hand5_o_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/p/\n",
            "  inflating: asl_split_dataset/val/p/hand1_p_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand1_p_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand2_p_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand2_p_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand2_p_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand2_p_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand3_p_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand4_p_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand5_p_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand5_p_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/p/hand5_p_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/q/\n",
            "  inflating: asl_split_dataset/val/q/hand1_q_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand1_q_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand2_q_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand2_q_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand2_q_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand2_q_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand3_q_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand4_q_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand5_q_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand5_q_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/q/hand5_q_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/r/\n",
            "  inflating: asl_split_dataset/val/r/hand1_r_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand1_r_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand2_r_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand2_r_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand2_r_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand2_r_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand3_r_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand4_r_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand5_r_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand5_r_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/r/hand5_r_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/s/\n",
            "  inflating: asl_split_dataset/val/s/hand1_s_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand1_s_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand2_s_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand2_s_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand2_s_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand2_s_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand3_s_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand4_s_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand5_s_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand5_s_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/s/hand5_s_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/t/\n",
            "  inflating: asl_split_dataset/val/t/hand1_t_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand1_t_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand1_t_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand2_t_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand2_t_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand2_t_right_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand2_t_right_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand3_t_dif_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand4_t_bot_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/t/hand5_t_bot_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/u/\n",
            "  inflating: asl_split_dataset/val/u/hand1_u_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand1_u_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand2_u_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand2_u_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand2_u_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand2_u_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand3_u_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand4_u_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand5_u_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand5_u_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/u/hand5_u_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/v/\n",
            "  inflating: asl_split_dataset/val/v/hand1_v_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand1_v_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand2_v_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand2_v_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand2_v_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand2_v_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand3_v_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand4_v_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand5_v_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand5_v_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/v/hand5_v_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/w/\n",
            "  inflating: asl_split_dataset/val/w/hand1_w_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand1_w_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand2_w_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand2_w_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand2_w_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand2_w_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand3_w_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand4_w_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand5_w_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand5_w_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/w/hand5_w_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/x/\n",
            "  inflating: asl_split_dataset/val/x/hand1_x_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand1_x_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand2_x_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand2_x_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand2_x_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand2_x_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand3_x_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand4_x_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand5_x_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand5_x_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/x/hand5_x_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/y/\n",
            "  inflating: asl_split_dataset/val/y/hand1_y_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand1_y_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand2_y_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand2_y_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand2_y_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand2_y_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand3_y_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand4_y_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand5_y_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand5_y_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/y/hand5_y_dif_seg_5_cropped.jpeg  \n",
            "   creating: asl_split_dataset/val/z/\n",
            "  inflating: asl_split_dataset/val/z/hand1_z_bot_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand1_z_left_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand2_z_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand2_z_left_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand2_z_right_seg_2_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand2_z_top_seg_1_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand3_z_dif_seg_5_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand4_z_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand5_z_bot_seg_4_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand5_z_dif_seg_3_cropped.jpeg  \n",
            "  inflating: asl_split_dataset/val/z/hand5_z_dif_seg_5_cropped.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BVdrHR6TJbF",
        "outputId": "20a5dad9-9cd4-4a9c-a5cb-d9115ff76abc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J_65GrQqSmGN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "class EnhancedHandLandmarkExtractor:\n",
        "    def __init__(self):\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.hands = self.mp_hands.Hands(\n",
        "            static_image_mode=True,\n",
        "            max_num_hands=1,\n",
        "            min_detection_confidence=0.3,\n",
        "            min_tracking_confidence=0.3\n",
        "        )\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "        self.finger_tips = [4, 8, 12, 16, 20]  # Thumb to pinky tips\n",
        "        self.finger_bases = [2, 5, 9, 13, 17]  # Thumb to pinky bases\n",
        "        self.palm_landmarks = [0, 1, 5, 9, 13, 17]  # Wrist and finger bases\n",
        "\n",
        "    def load_dataset(self, data_dir, batch_size=32):\n",
        "        dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            data_dir,\n",
        "            image_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            label_mode='categorical',\n",
        "            color_mode='rgb',\n",
        "            interpolation='bilinear'\n",
        "        )\n",
        "\n",
        "        def normalize_img(image, label):\n",
        "            return tf.cast(image, tf.float32) / 255.0, label\n",
        "\n",
        "        return dataset.map(normalize_img)\n",
        "\n",
        "    def calculate_finger_angles(self, landmarks_array):\n",
        "        angles = []\n",
        "        # For each finger (except thumb)\n",
        "        for finger_idx in range(1, 5):\n",
        "            base = finger_idx * 4 + 1\n",
        "            mid = finger_idx * 4 + 2\n",
        "            tip = finger_idx * 4 + 3\n",
        "\n",
        "            # Get vectors for the two segments\n",
        "            v1 = landmarks_array[mid] - landmarks_array[base]\n",
        "            v2 = landmarks_array[tip] - landmarks_array[mid]\n",
        "\n",
        "            # Calculate angle\n",
        "            cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "            angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
        "            angles.append(angle)\n",
        "\n",
        "        # Special case for thumb\n",
        "        thumb_base = landmarks_array[1]\n",
        "        thumb_mid = landmarks_array[2]\n",
        "        thumb_tip = landmarks_array[4]\n",
        "\n",
        "        v1 = thumb_mid - thumb_base\n",
        "        v2 = thumb_tip - thumb_mid\n",
        "        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "        thumb_angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
        "        angles.append(thumb_angle)\n",
        "\n",
        "        return np.array(angles)\n",
        "\n",
        "    def calculate_finger_lengths(self, landmarks_array):\n",
        "        lengths = []\n",
        "        for finger_idx in range(5):  # For all fingers including thumb\n",
        "            if finger_idx == 0:  # Thumb\n",
        "                base = 1\n",
        "                tip = 4\n",
        "            else:\n",
        "                base = finger_idx * 4 + 1\n",
        "                tip = finger_idx * 4 + 4\n",
        "\n",
        "            length = np.linalg.norm(landmarks_array[tip] - landmarks_array[base])\n",
        "            lengths.append(length)\n",
        "\n",
        "        # Normalize by palm size\n",
        "        palm_size = np.linalg.norm(landmarks_array[0] - landmarks_array[5])\n",
        "        normalized_lengths = np.array(lengths) / palm_size\n",
        "\n",
        "        return normalized_lengths\n",
        "\n",
        "    def calculate_palm_features(self, landmarks_array):\n",
        "        # Calculate palm area using convex hull\n",
        "        palm_points = landmarks_array[self.palm_landmarks]\n",
        "        hull = cv2.convexHull(palm_points[:, :2].astype(np.float32))\n",
        "        palm_area = cv2.contourArea(hull)\n",
        "\n",
        "        # Calculate palm orientation\n",
        "        wrist_to_middle = landmarks_array[9] - landmarks_array[0]\n",
        "        palm_angle = np.arctan2(wrist_to_middle[1], wrist_to_middle[0])\n",
        "\n",
        "        # Calculate palm width/height ratio\n",
        "        palm_width = np.linalg.norm(landmarks_array[5] - landmarks_array[17])\n",
        "        palm_height = np.linalg.norm(landmarks_array[0] - landmarks_array[9])\n",
        "        palm_ratio = palm_width / palm_height if palm_height != 0 else 0\n",
        "\n",
        "        return np.array([palm_area, palm_angle, palm_ratio])\n",
        "\n",
        "    def calculate_finger_distance_matrix(self, landmarks_array):\n",
        "        fingertip_positions = landmarks_array[self.finger_tips]\n",
        "        distances = pdist(fingertip_positions)\n",
        "        return distances\n",
        "\n",
        "    def extract_enhanced_features(self, landmarks):\n",
        "        landmarks_array = landmarks.reshape(-1, 3)\n",
        "\n",
        "        # Basic landmark positions (normalized)\n",
        "        basic_features = landmarks.flatten()\n",
        "\n",
        "        # Calculate additional features\n",
        "        finger_angles = self.calculate_finger_angles(landmarks_array)\n",
        "        finger_lengths = self.calculate_finger_lengths(landmarks_array)\n",
        "        palm_features = self.calculate_palm_features(landmarks_array)\n",
        "        fingertip_distances = self.calculate_finger_distance_matrix(landmarks_array)\n",
        "\n",
        "        enhanced_features = np.concatenate([\n",
        "            basic_features,          # Original landmark positions (63 features)\n",
        "            finger_angles,           # Angles between finger segments (5 features)\n",
        "            finger_lengths,          # Normalized finger lengths (5 features)\n",
        "            palm_features,           # Palm characteristics (3 features)\n",
        "            fingertip_distances      # Pairwise fingertip distances (10 features)\n",
        "        ])\n",
        "\n",
        "        return enhanced_features\n",
        "\n",
        "    def extract_landmarks(self, image):\n",
        "        image_mp = tf.cast(image * 255, tf.uint8)\n",
        "        if isinstance(image_mp, tf.Tensor):\n",
        "            image_mp = image_mp.numpy()\n",
        "\n",
        "        results = self.hands.process(image_mp)\n",
        "\n",
        "        features = np.zeros(86)  # 63 original + 23 enhanced features\n",
        "\n",
        "        if results.multi_hand_landmarks:\n",
        "            landmarks = results.multi_hand_landmarks[0]\n",
        "            # Extract basic landmarks\n",
        "            basic_features = np.zeros(63)\n",
        "            for idx, landmark in enumerate(landmarks.landmark):\n",
        "                basic_features[idx*3:(idx*3)+3] = [landmark.x, landmark.y, landmark.z]\n",
        "\n",
        "            # Calculate enhanced features\n",
        "            features = self.extract_enhanced_features(basic_features)\n",
        "\n",
        "            # visualization\n",
        "            annotated_image = image_mp.copy()\n",
        "            self.mp_drawing.draw_landmarks(\n",
        "                annotated_image,\n",
        "                landmarks,\n",
        "                self.mp_hands.HAND_CONNECTIONS\n",
        "            )\n",
        "            return features, annotated_image, True\n",
        "\n",
        "        return features, image_mp, False\n",
        "\n",
        "    def augment_landmarks(self, features):\n",
        "        augmented_features = []\n",
        "\n",
        "        if np.any(features):\n",
        "            # Original features\n",
        "            augmented_features.append(features)\n",
        "\n",
        "            # More subtle rotation variations\n",
        "            for angle in [-20, -10, 10, 20]:\n",
        "                rotated = self._rotate_landmarks(features[:63].copy(), angle)\n",
        "                enhanced_rotated = self.extract_enhanced_features(rotated)\n",
        "                augmented_features.append(enhanced_rotated)\n",
        "\n",
        "            # Scale variations\n",
        "            for scale in [0.85, 0.95, 1.05, 1.15]:\n",
        "                scaled = self._scale_landmarks(features[:63].copy(), scale)\n",
        "                enhanced_scaled = self.extract_enhanced_features(scaled)\n",
        "                augmented_features.append(enhanced_scaled)\n",
        "\n",
        "            # Controlled noise addition\n",
        "            for _ in range(3):\n",
        "                noisy = self._add_noise(features[:63].copy(), 0.005)\n",
        "                enhanced_noisy = self.extract_enhanced_features(noisy)\n",
        "                augmented_features.append(enhanced_noisy)\n",
        "        else:\n",
        "            augmented_features.append(features)\n",
        "\n",
        "        return augmented_features\n",
        "\n",
        "    def _rotate_landmarks(self, landmarks, angle):\n",
        "        landmarks_reshaped = landmarks.reshape(-1, 3)\n",
        "        center = np.mean(landmarks_reshaped[:, :2], axis=0)\n",
        "        angle_rad = np.radians(angle)\n",
        "\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(angle_rad), -np.sin(angle_rad)],\n",
        "            [np.sin(angle_rad), np.cos(angle_rad)]\n",
        "        ])\n",
        "\n",
        "        centered = landmarks_reshaped[:, :2] - center\n",
        "        rotated = np.dot(centered, rotation_matrix.T)\n",
        "        landmarks_reshaped[:, :2] = rotated + center\n",
        "\n",
        "        return landmarks_reshaped.flatten()\n",
        "\n",
        "    def _scale_landmarks(self, landmarks, scale_factor):\n",
        "        landmarks_reshaped = landmarks.reshape(-1, 3)\n",
        "        center = np.mean(landmarks_reshaped[:, :2], axis=0)\n",
        "\n",
        "        centered = landmarks_reshaped[:, :2] - center\n",
        "        scaled = centered * scale_factor\n",
        "        landmarks_reshaped[:, :2] = scaled + center\n",
        "\n",
        "        return landmarks_reshaped.flatten()\n",
        "\n",
        "    def _add_noise(self, landmarks, noise_factor=0.01):\n",
        "        noise = np.random.normal(0, noise_factor, landmarks.shape)\n",
        "        return landmarks + noise\n",
        "\n",
        "    def save_features(self, features, labels, filename):\n",
        "        df = pd.DataFrame(features)\n",
        "        df['label'] = labels.argmax(axis=1)  # Convert one-hot to label index\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Saved {len(df)} samples to {filename}\")\n",
        "\n",
        "\n",
        "    def process_dataset(self, dataset, augment=True, visualize=False):\n",
        "        features_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        for images, labels in tqdm(dataset, desc=\"Processing dataset\"):\n",
        "            for img, label in zip(images, labels):\n",
        "                # Extract enhanced features\n",
        "                features, annotated_image, detected = self.extract_landmarks(img)\n",
        "\n",
        "                if augment:\n",
        "                    augmented_features = self.augment_landmarks(features)\n",
        "                    features_list.extend(augmented_features)\n",
        "                    labels_list.extend([label] * len(augmented_features))\n",
        "                else:\n",
        "                    features_list.append(features)\n",
        "                    labels_list.append(label)\n",
        "\n",
        "                if visualize and len(features_list) <= 3:\n",
        "                    plt.figure(figsize=(10, 5))\n",
        "                    plt.subplot(1, 2, 1)\n",
        "                    plt.imshow(tf.cast(img * 255, tf.uint8))\n",
        "                    plt.title('Original Image')\n",
        "                    plt.axis('off')\n",
        "\n",
        "                    plt.subplot(1, 2, 2)\n",
        "                    plt.imshow(annotated_image)\n",
        "                    plt.title('Detected Landmarks' if detected else 'No Landmarks Detected')\n",
        "                    plt.axis('off')\n",
        "                    plt.show()\n",
        "\n",
        "        return np.array(features_list), np.array(labels_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    extractor = EnhancedHandLandmarkExtractor()\n",
        "\n",
        "       # Load datasets\n",
        "    print(\"Loading datasets...\")\n",
        "    train_dataset = extractor.load_dataset('asl_split_dataset/train')\n",
        "    val_dataset = extractor.load_dataset('asl_split_dataset/val')\n",
        "    test_dataset = extractor.load_dataset('asl_split_dataset/test')\n",
        "\n",
        "    # Process datasets\n",
        "    print(\"Processing training dataset...\")\n",
        "    train_features, train_labels = extractor.process_dataset(train_dataset, augment=True, visualize=True)\n",
        "\n",
        "    print(\"Processing validation dataset...\")\n",
        "    val_features, val_labels = extractor.process_dataset(val_dataset, augment=True, visualize=False)\n",
        "\n",
        "    print(\"Processing test dataset...\")\n",
        "    test_features, test_labels = extractor.process_dataset(test_dataset, augment=False, visualize=False)\n",
        "\n",
        "    # Save features\n",
        "    extractor.save_features(train_features, train_labels, 'train_features.csv')\n",
        "    extractor.save_features(val_features, val_labels, 'val_features.csv')\n",
        "    extractor.save_features(test_features, test_labels, 'test_features.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LGOiq5Oy4V8",
        "outputId": "402d2fac-b75e-481a-a1ef-531995f22516"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Found 1581 files belonging to 36 classes.\n",
            "Found 395 files belonging to 36 classes.\n",
            "Found 539 files belonging to 36 classes.\n",
            "Processing training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing dataset: 100%|██████████| 50/50 [01:10<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing validation dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing dataset: 100%|██████████| 13/13 [00:13<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing dataset: 100%|██████████| 17/17 [00:17<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 15364 samples to train_features.csv\n",
            "Saved 3893 samples to val_features.csv\n",
            "Saved 539 samples to test_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def visualize_dataset_samples(extractor, dataset, output_dir='visualization_samples',\n",
        "                            num_samples_per_class=3):\n",
        "    \"\"\"Generate visualization samples from the dataset\"\"\"\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/original\", exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/landmarks\", exist_ok=True)\n",
        "\n",
        "    # Dictionary to keep track of samples per class\n",
        "    class_counts = {}\n",
        "    visualization_data = []\n",
        "\n",
        "    for images, labels in tqdm(dataset, desc=\"Generating visualizations\"):\n",
        "        for img, label in zip(images, labels):\n",
        "            # Get class index\n",
        "            class_idx = np.argmax(label)\n",
        "            class_name = chr(65 + class_idx) if class_idx >= 10 else str(class_idx)\n",
        "\n",
        "            # Skip if we have enough samples for this class\n",
        "            if class_name in class_counts and class_counts[class_name] >= num_samples_per_class:\n",
        "                continue\n",
        "\n",
        "            # Initialize class count\n",
        "            if class_name not in class_counts:\n",
        "                class_counts[class_name] = 0\n",
        "\n",
        "            # Extract landmarks and get visualization\n",
        "            features, annotated_image, detected = extractor.extract_landmarks(img)\n",
        "\n",
        "            if detected:\n",
        "                # Save original image\n",
        "                original_path = f\"{output_dir}/original/{class_name}_{class_counts[class_name]}.png\"\n",
        "                landmark_path = f\"{output_dir}/landmarks/{class_name}_{class_counts[class_name]}.png\"\n",
        "\n",
        "                # Save original image\n",
        "                plt.imsave(original_path, tf.cast(img * 255, tf.uint8).numpy().astype(np.uint8))\n",
        "\n",
        "                # Save landmark visualization\n",
        "                plt.imsave(landmark_path, annotated_image)\n",
        "\n",
        "                # Add to visualization data\n",
        "                visualization_data.append({\n",
        "                    'label': class_name,\n",
        "                    'original': original_path,\n",
        "                    'landmark': landmark_path,\n",
        "                    'features': features\n",
        "                })\n",
        "\n",
        "                class_counts[class_name] += 1\n",
        "\n",
        "            # Check if we have enough samples\n",
        "            if len(class_counts) == 36 and all(count >= num_samples_per_class for count in class_counts.values()):\n",
        "                break\n",
        "\n",
        "    # Sort visualization data by label\n",
        "    visualization_data.sort(key=lambda x: x['label'])\n",
        "\n",
        "    # Create overview visualization\n",
        "    create_overview_visualization(visualization_data, output_dir)\n",
        "\n",
        "    return visualization_data\n",
        "\n",
        "def create_overview_visualization(visualization_data, output_dir):\n",
        "    \"\"\"Create an overview grid of all samples\"\"\"\n",
        "    # Group data by class\n",
        "    class_groups = {}\n",
        "    for item in visualization_data:\n",
        "        if item['label'] not in class_groups:\n",
        "            class_groups[item['label']] = []\n",
        "        class_groups[item['label']].append(item)\n",
        "\n",
        "    # Calculate grid layout\n",
        "    num_classes = len(class_groups)\n",
        "    samples_per_class = len(next(iter(class_groups.values())))\n",
        "\n",
        "    # Create figure with enough space for all samples\n",
        "    fig = plt.figure(figsize=(samples_per_class * 6, num_classes * 3))\n",
        "\n",
        "    # Plot each class\n",
        "    for class_idx, (class_label, samples) in enumerate(sorted(class_groups.items())):\n",
        "        for sample_idx, sample in enumerate(samples):\n",
        "            # Plot original image\n",
        "            plt.subplot(num_classes, samples_per_class * 2, class_idx * samples_per_class * 2 + sample_idx * 2 + 1)\n",
        "            img = plt.imread(sample['original'])\n",
        "            plt.imshow(img)\n",
        "            if sample_idx == 0:\n",
        "                plt.ylabel(f\"Class {class_label}\", rotation=0, labelpad=40)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot landmark image\n",
        "            plt.subplot(num_classes, samples_per_class * 2, class_idx * samples_per_class * 2 + sample_idx * 2 + 2)\n",
        "            landmarks = plt.imread(sample['landmark'])\n",
        "            plt.imshow(landmarks)\n",
        "            plt.title(\"Landmarks\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{output_dir}/overview.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "extractor = EnhancedHandLandmarkExtractor()\n",
        "dataset = extractor.load_dataset('asl_split_dataset/train')\n",
        "\n",
        "visualization_data = visualize_dataset_samples(\n",
        "        extractor,\n",
        "        dataset,\n",
        "        output_dir='asl_visualization',\n",
        "        num_samples_per_class=3\n",
        "    )\n",
        "\n",
        "print(f\"Generated visualizations for {len(visualization_data)} samples\")\n",
        "print(\"Results saved in 'asl_visualization' directory\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHWC6T69O2Vt",
        "outputId": "1d15ff38-1429-47c4-a339-2e8414020241"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1581 files belonging to 36 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating visualizations: 100%|██████████| 50/50 [00:20<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated visualizations for 108 samples\n",
            "Results saved in 'asl_visualization' directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, BatchNormalization, Input,\n",
        "    Multiply, Add, LayerNormalization, Activation,\n",
        "    Lambda, Concatenate\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,\n",
        "    TensorBoard\n",
        ")\n",
        "import optuna\n",
        "import pickle\n",
        "import shap\n",
        "from collections import defaultdict\n",
        "\n",
        "def configure_gpu():\n",
        "    \"\"\"Configure GPU settings before any TensorFlow operations\"\"\"\n",
        "    try:\n",
        "        physical_devices = tf.config.list_physical_devices('GPU')\n",
        "        if physical_devices:\n",
        "            for device in physical_devices:\n",
        "                tf.config.experimental.set_memory_growth(device, True)\n",
        "            print(f\"Found {len(physical_devices)} GPU(s). Memory growth enabled.\")\n",
        "            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "            print(\"Mixed precision training enabled\")\n",
        "        else:\n",
        "            print(\"No GPU found. Using CPU for training.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU configuration error: {str(e)}\")\n",
        "        print(\"Falling back to CPU training\")\n",
        "\n",
        "class GestureAnalyzer:\n",
        "    def __init__(self, num_classes=36, input_dim=86):\n",
        "        self.num_classes = num_classes\n",
        "        self.input_dim = input_dim\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.class_names =[str(i) for i in range(10)]+ [chr(i) for i in range(65, 65+26)]\n",
        "\n",
        "        # Create directories for saving results\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "        os.makedirs('analysis', exist_ok=True)\n",
        "        os.makedirs('plots', exist_ok=True)\n",
        "\n",
        "    def attention_block(self, x, units):\n",
        "        \"\"\"Custom attention mechanism for feature importance\"\"\"\n",
        "        attention = Dense(units, activation='tanh')(x)\n",
        "        attention = Dense(units, activation='sigmoid')(attention)\n",
        "        return Multiply()([x, attention])\n",
        "\n",
        "    def residual_block(self, x, units, dropout_rate):\n",
        "        \"\"\"Residual block with pre-activation\"\"\"\n",
        "        # Store input for residual connection\n",
        "        input_tensor = x\n",
        "\n",
        "        # First sub-block\n",
        "        x = LayerNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Dense(units)(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        # Second sub-block\n",
        "        x = LayerNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Dense(units)(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        # Adjust input dimensions if needed\n",
        "        if input_tensor.shape[-1] != units:\n",
        "            input_tensor = Dense(units)(input_tensor)\n",
        "\n",
        "        # Add residual connection\n",
        "        x = Add()([x, input_tensor])\n",
        "        return x\n",
        "\n",
        "    def load_and_preprocess_data(self):\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # Load datasets\n",
        "        train_df = pd.read_csv('train_features.csv')\n",
        "        val_df = pd.read_csv('val_features.csv')\n",
        "        test_df = pd.read_csv('test_features.csv')\n",
        "\n",
        "        # Create feature names for analysis\n",
        "        self.feature_names = [f'landmark_{i}' for i in range(63)]\n",
        "        self.feature_names.extend([f'geometric_{i}' for i in range(self.input_dim - 63)])\n",
        "\n",
        "        # Separate features and labels\n",
        "        X_train = train_df.drop('label', axis=1).values\n",
        "        y_train = train_df['label'].values\n",
        "\n",
        "        X_val = val_df.drop('label', axis=1).values\n",
        "        y_val = val_df['label'].values\n",
        "\n",
        "        X_test = test_df.drop('label', axis=1).values\n",
        "        y_test = test_df['label'].values\n",
        "\n",
        "        # Scale features\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val = self.scaler.transform(X_val)\n",
        "        X_test = self.scaler.transform(X_test)\n",
        "\n",
        "        # Save scaler\n",
        "        with open('models/feature_scaler.pkl', 'wb') as f:\n",
        "            pickle.dump(self.scaler, f)\n",
        "        print(\"Scaler saved to models/feature_scaler.pkl\")\n",
        "\n",
        "        # Convert to float32 and categorical labels\n",
        "        X_train = X_train.astype(np.float32)\n",
        "        X_val = X_val.astype(np.float32)\n",
        "        X_test = X_test.astype(np.float32)\n",
        "\n",
        "        y_train = tf.keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_val = tf.keras.utils.to_categorical(y_val, self.num_classes)\n",
        "        y_test = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "    def create_model(self, params):\n",
        "        inputs = Input(shape=(self.input_dim,))\n",
        "\n",
        "        # Split features\n",
        "        landmarks = Lambda(lambda x: x[:, :63])(inputs)\n",
        "        enhanced = Lambda(lambda x: x[:, 63:])(inputs)\n",
        "\n",
        "        # Process landmark features with attention\n",
        "        x1 = Dense(params['units_1'])(landmarks)\n",
        "        x1 = self.attention_block(x1, params['units_1'])\n",
        "        x1 = self.residual_block(x1, params['units_1'], params['dropout_1'])\n",
        "\n",
        "        # Process enhanced features\n",
        "        x2 = Dense(params['units_2'])(enhanced)\n",
        "        x2 = self.attention_block(x2, params['units_2'])\n",
        "        x2 = self.residual_block(x2, params['units_2'], params['dropout_2'])\n",
        "\n",
        "        # Combine features\n",
        "        x = Concatenate()([x1, x2])\n",
        "        x = Dense(params['units_3'])(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Dropout(params['dropout_3'])(x)\n",
        "\n",
        "        outputs = Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        optimizer = Adam(learning_rate=params['learning_rate'])\n",
        "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
        "            optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_and_evaluate(self):\n",
        "        # Load data\n",
        "        (X_train, y_train), (X_val, y_val), (X_test, y_test) = self.load_and_preprocess_data()\n",
        "\n",
        "        # Optimize hyperparameters\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(lambda trial: self.objective(trial, X_train, y_train, X_val, y_val),\n",
        "                      n_trials=10)\n",
        "\n",
        "        # Train final model\n",
        "        self.model = self.create_model(study.best_params)\n",
        "\n",
        "        # Set up callbacks\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5),\n",
        "            ModelCheckpoint('models/best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
        "            TensorBoard(log_dir=f\"logs/fit/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
        "        ]\n",
        "\n",
        "        # Train model\n",
        "        self.history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=100,\n",
        "            batch_size=32,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluate on test set\n",
        "        self.perform_analysis(X_test, y_test)\n",
        "\n",
        "\n",
        "    def objective(self, trial, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Optuna objective function for hyperparameter optimization\"\"\"\n",
        "        params = {\n",
        "            'units_1': trial.suggest_int('units_1', 128, 512),\n",
        "            'units_2': trial.suggest_int('units_2', 64, 256),\n",
        "            'units_3': trial.suggest_int('units_3', 32, 128),\n",
        "            'dropout_1': trial.suggest_float('dropout_1', 0.2, 0.5),\n",
        "            'dropout_2': trial.suggest_float('dropout_2', 0.2, 0.5),\n",
        "            'dropout_3': trial.suggest_float('dropout_3', 0.2, 0.5),\n",
        "            'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
        "            'batch_size': trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "        }\n",
        "\n",
        "        model = self.create_model(params)\n",
        "\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=50,\n",
        "            batch_size=params['batch_size'],\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0\n",
        "        )\n",
        "        plot_final_metrics(history)\n",
        "\n",
        "        return max(history.history['val_accuracy'])\n",
        "\n",
        "    def perform_analysis(self, X_test, y_test):\n",
        "        # Get predictions\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.class_names,\n",
        "                   yticklabels=self.class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.savefig('plots/confusion_matrix.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Analyze misclassifications\n",
        "        misclass_analysis = self.analyze_misclassifications(y_true_classes, y_pred_classes)\n",
        "\n",
        "        # Feature importance analysis using SHAP\n",
        "        # explainer = shap.DeepExplainer(self.model, X_test[:100])\n",
        "        # shap_values = explainer.shap_values(X_test[:100])\n",
        "\n",
        "        # # Plot SHAP summary\n",
        "        # plt.figure(figsize=(12, 8))\n",
        "        # shap.summary_plot(shap_values, X_test[:100], feature_names=self.feature_names,\n",
        "        #                  show=False)\n",
        "        plt.savefig('plots/shap_summary.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Generate and save analysis report\n",
        "        self.generate_analysis_report(conf_matrix, misclass_analysis, y_true_classes, y_pred_classes)\n",
        "\n",
        "    def analyze_misclassifications(self, y_true, y_pred):\n",
        "        misclassifications = defaultdict(list)\n",
        "        for true, pred in zip(y_true, y_pred):\n",
        "            if true != pred:\n",
        "                misclassifications[self.class_names[true]].append(self.class_names[pred])\n",
        "\n",
        "        analysis = {}\n",
        "        for true_class, pred_classes in misclassifications.items():\n",
        "            common_confusions = pd.Series(pred_classes).value_counts().head(3)\n",
        "            analysis[true_class] = {\n",
        "                'total_errors': len(pred_classes),\n",
        "                'common_confusions': common_confusions.to_dict()\n",
        "            }\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def generate_analysis_report(self, conf_matrix, misclass_analysis, y_true, y_pred):\n",
        "        report = classification_report(y_true, y_pred, target_names=self.class_names)\n",
        "\n",
        "        with open('analysis/model_analysis.txt', 'w') as f:\n",
        "            f.write(\"Hand Gesture Recognition Model Analysis\\n\")\n",
        "            f.write(\"=====================================\\n\\n\")\n",
        "\n",
        "            f.write(\"Classification Report:\\n\")\n",
        "            f.write(report)\n",
        "            f.write(\"\\n\\n\")\n",
        "\n",
        "            f.write(\"Misclassification Analysis:\\n\")\n",
        "            f.write(\"-------------------------\\n\")\n",
        "            for class_name, analysis in misclass_analysis.items():\n",
        "                f.write(f\"\\nClass {class_name}:\\n\")\n",
        "                f.write(f\"Total errors: {analysis['total_errors']}\\n\")\n",
        "                f.write(\"Most common confusions:\\n\")\n",
        "                for confused_with, count in analysis['common_confusions'].items():\n",
        "                    f.write(f\"  - Confused with {confused_with}: {count} times\\n\")\n",
        "\n",
        "            f.write(\"\\nModel Architecture:\\n\")\n",
        "            f.write(\"------------------\\n\")\n",
        "            self.model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "\n",
        "def plot_final_metrics(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy',\n",
        "             color='#2563eb', linewidth=2)\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy',\n",
        "             color='#16a34a', linewidth=2)\n",
        "    plt.title('Model Accuracy', fontsize=12, pad=10)\n",
        "    plt.xlabel('Epoch', fontsize=10)\n",
        "    plt.ylabel('Accuracy', fontsize=10)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss',\n",
        "             color='#dc2626', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss',\n",
        "             color='#ea580c', linewidth=2)\n",
        "    plt.title('Model Loss', fontsize=12, pad=10)\n",
        "    plt.xlabel('Epoch', fontsize=10)\n",
        "    plt.ylabel('Loss', fontsize=10)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('plots/training_metrics.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    configure_gpu()\n",
        "\n",
        "    print(\"Starting comprehensive gesture recognition analysis...\")\n",
        "    analyzer = GestureAnalyzer()\n",
        "    analyzer.train_and_evaluate()\n",
        "\n",
        "    print(\"\\nAnalysis completed. Results saved in:\")\n",
        "    print(\"- models/best_model.keras\")\n",
        "    print(\"- models/feature_scaler.pkl\")\n",
        "    print(\"- plots/confusion_matrix.png\")\n",
        "    print(\"- plots/shap_summary.png\")\n",
        "    print(\"- analysis/model_analysis.txt\")\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WxBV9iTiXO61",
        "outputId": "a3d71456-0bf6-4606-eff6-7de01e089c6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU configuration error: Physical devices cannot be modified after being initialized\n",
            "Falling back to CPU training\n",
            "Starting comprehensive gesture recognition analysis...\n",
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-12 14:07:51,897] A new study created in memory with name: no-name-d8f7b587-d513-4f95-b929-4d93aff00517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler saved to models/feature_scaler.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2a355b677f3e>:216: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
            "[I 2024-12-12 14:08:42,267] Trial 0 finished with value: 0.9167736768722534 and parameters: {'units_1': 174, 'units_2': 153, 'units_3': 59, 'dropout_1': 0.4497069903640959, 'dropout_2': 0.3700507102030728, 'dropout_3': 0.3444633884528753, 'learning_rate': 0.00011641613627571961, 'batch_size': 64}. Best is trial 0 with value: 0.9167736768722534.\n",
            "[I 2024-12-12 14:09:59,339] Trial 1 finished with value: 0.9337272047996521 and parameters: {'units_1': 435, 'units_2': 228, 'units_3': 71, 'dropout_1': 0.2201455098789232, 'dropout_2': 0.21567594520644612, 'dropout_3': 0.3546124040979851, 'learning_rate': 0.00019746134230359764, 'batch_size': 32}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:10:50,541] Trial 2 finished with value: 0.9278191328048706 and parameters: {'units_1': 182, 'units_2': 110, 'units_3': 114, 'dropout_1': 0.2072776698883728, 'dropout_2': 0.20392595401328192, 'dropout_3': 0.37749136756729684, 'learning_rate': 0.00016185989957011494, 'batch_size': 128}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:12:56,284] Trial 3 finished with value: 0.9221680164337158 and parameters: {'units_1': 315, 'units_2': 161, 'units_3': 110, 'dropout_1': 0.4601129602988018, 'dropout_2': 0.3882485732682129, 'dropout_3': 0.3642549981743382, 'learning_rate': 1.6821338731130524e-05, 'batch_size': 32}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:13:50,771] Trial 4 finished with value: 0.8759311437606812 and parameters: {'units_1': 476, 'units_2': 97, 'units_3': 88, 'dropout_1': 0.38525625872184166, 'dropout_2': 0.34684285152455085, 'dropout_3': 0.48986072752567833, 'learning_rate': 1.2633028016637388e-05, 'batch_size': 128}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:14:35,485] Trial 5 finished with value: 0.9260210394859314 and parameters: {'units_1': 498, 'units_2': 180, 'units_3': 32, 'dropout_1': 0.2604314402734885, 'dropout_2': 0.3032340048590547, 'dropout_3': 0.3704965406180256, 'learning_rate': 0.0008343698143748607, 'batch_size': 64}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:15:46,818] Trial 6 finished with value: 0.9206267595291138 and parameters: {'units_1': 302, 'units_2': 211, 'units_3': 111, 'dropout_1': 0.4956466638362881, 'dropout_2': 0.2957666320911176, 'dropout_3': 0.3557872933190704, 'learning_rate': 0.0004678383218812385, 'batch_size': 32}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:17:03,770] Trial 7 finished with value: 0.9129206538200378 and parameters: {'units_1': 163, 'units_2': 148, 'units_3': 50, 'dropout_1': 0.3679206326353942, 'dropout_2': 0.4984454707848192, 'dropout_3': 0.3593470555785583, 'learning_rate': 3.939551029986842e-05, 'batch_size': 64}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:18:04,667] Trial 8 finished with value: 0.9203699231147766 and parameters: {'units_1': 273, 'units_2': 223, 'units_3': 116, 'dropout_1': 0.48630599335680585, 'dropout_2': 0.20004505319805704, 'dropout_3': 0.37404857008418346, 'learning_rate': 0.00038366275283917723, 'batch_size': 64}. Best is trial 1 with value: 0.9337272047996521.\n",
            "[I 2024-12-12 14:19:20,288] Trial 9 finished with value: 0.9178012013435364 and parameters: {'units_1': 395, 'units_2': 130, 'units_3': 105, 'dropout_1': 0.4062584624274321, 'dropout_2': 0.24925361834992812, 'dropout_3': 0.2698976334268215, 'learning_rate': 3.553865794879096e-05, 'batch_size': 128}. Best is trial 1 with value: 0.9337272047996521.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.5658 - loss: 1.8672 - val_accuracy: 0.8664 - val_loss: 0.4931 - learning_rate: 1.9746e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8956 - loss: 0.5681 - val_accuracy: 0.8942 - val_loss: 0.3458 - learning_rate: 1.9746e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 0.3207 - val_accuracy: 0.9119 - val_loss: 0.2966 - learning_rate: 1.9746e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9488 - loss: 0.2534 - val_accuracy: 0.9163 - val_loss: 0.3011 - learning_rate: 1.9746e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9642 - loss: 0.1765 - val_accuracy: 0.9181 - val_loss: 0.3011 - learning_rate: 1.9746e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.1596 - val_accuracy: 0.9160 - val_loss: 0.3028 - learning_rate: 1.9746e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9679 - loss: 0.1366 - val_accuracy: 0.9139 - val_loss: 0.3310 - learning_rate: 1.9746e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.1320 - val_accuracy: 0.9201 - val_loss: 0.3384 - learning_rate: 1.9746e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.1055 - val_accuracy: 0.9217 - val_loss: 0.3539 - learning_rate: 1.9746e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9714 - loss: 0.1088 - val_accuracy: 0.9240 - val_loss: 0.3624 - learning_rate: 1.9746e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.1013 - val_accuracy: 0.9165 - val_loss: 0.3792 - learning_rate: 1.9746e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.1014 - val_accuracy: 0.9132 - val_loss: 0.3670 - learning_rate: 1.9746e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.0988 - val_accuracy: 0.9173 - val_loss: 0.4008 - learning_rate: 1.9746e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9783 - loss: 0.0771 - val_accuracy: 0.9178 - val_loss: 0.4053 - learning_rate: 1.9746e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0801 - val_accuracy: 0.9309 - val_loss: 0.3645 - learning_rate: 1.9746e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.0745 - val_accuracy: 0.9114 - val_loss: 0.4333 - learning_rate: 1.9746e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.0834 - val_accuracy: 0.9209 - val_loss: 0.3921 - learning_rate: 1.9746e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0726 - val_accuracy: 0.9227 - val_loss: 0.3927 - learning_rate: 1.9746e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9752 - loss: 0.0958 - val_accuracy: 0.9163 - val_loss: 0.4404 - learning_rate: 1.9746e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9773 - loss: 0.0806 - val_accuracy: 0.9132 - val_loss: 0.4661 - learning_rate: 1.9746e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0809 - val_accuracy: 0.9211 - val_loss: 0.4252 - learning_rate: 3.9492e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9794 - loss: 0.0704 - val_accuracy: 0.9178 - val_loss: 0.4452 - learning_rate: 3.9492e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0743 - val_accuracy: 0.9204 - val_loss: 0.4464 - learning_rate: 3.9492e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9815 - loss: 0.0631 - val_accuracy: 0.9209 - val_loss: 0.4343 - learning_rate: 3.9492e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0764 - val_accuracy: 0.9181 - val_loss: 0.4555 - learning_rate: 3.9492e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0656 - val_accuracy: 0.9193 - val_loss: 0.4488 - learning_rate: 7.8985e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9819 - loss: 0.0653 - val_accuracy: 0.9204 - val_loss: 0.4500 - learning_rate: 7.8985e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0690 - val_accuracy: 0.9199 - val_loss: 0.4471 - learning_rate: 7.8985e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.0666 - val_accuracy: 0.9214 - val_loss: 0.4447 - learning_rate: 7.8985e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0653 - val_accuracy: 0.9209 - val_loss: 0.4459 - learning_rate: 7.8985e-06\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis completed. Results saved in:\n",
            "- models/best_model.keras\n",
            "- models/feature_scaler.pkl\n",
            "- plots/confusion_matrix.png\n",
            "- plots/shap_summary.png\n",
            "- analysis/model_analysis.txt\n"
          ]
        }
      ]
    }
  ]
}